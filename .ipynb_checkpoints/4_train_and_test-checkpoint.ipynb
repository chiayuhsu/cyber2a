{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "cd55a276-85ca-4530-a224-12c0ac910e54",
   "metadata": {},
   "source": [
    "## 5. Training loop\n",
    "\n",
    "The provided training loop is responsible for iteratively adjusting the model's parameters to minimize the loss and improve performance. This loop includes both training and validation phases for a specified number of epochs, allowing assessment of the model's performance on unseen data after each epoch.\n",
    "\n",
    "#### Key Steps in the Training Loop:\n",
    "\n",
    "1. **Epoch Loop**: The outer loop runs for a specified number of epochs, where each epoch signifies a complete pass through the training dataset.\n",
    "\n",
    "2. **Training Phase**:\n",
    "   - The model is set to training mode using `model.train()`, which ensures that layers like dropout and batch normalization operate in training mode.\n",
    "   - For each batch in the `train_loader`, the inputs and labels are transferred to the appropriate device (GPU or CPU).\n",
    "   - Gradients are zeroed using `optimizer.zero_grad()` to prevent accumulation from previous iterations.\n",
    "   - The model makes predictions which are compared against the true labels using the loss function (`criterion`).\n",
    "   - Backpropagation is used to compute gradients, and the optimizer updates the model parameters.\n",
    "\n",
    "3. **Loss Calculation**:\n",
    "   - The running loss is accumulated to compute the average loss for the epoch, which is printed to monitor training progress.\n",
    "\n",
    "4. **Validation Phase**:\n",
    "   - The model is switched to evaluation mode with `model.eval()`, ensuring that layers behave accordingly (e.g., no dropout).\n",
    "   - The validation loop computes the model's accuracy on the validation dataset without updating the model parameters (`torch.no_grad()` ensures no gradients are calculated).\n",
    "   - The validation accuracy is printed to assess how well the model generalizes to unseen data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "02a9a5ec-b37f-482b-b02f-cdeb6a61f3fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "def train(model, criterion, optimizer, train_loader, val_loader, num_epochs=5):\n",
    "    \"\"\"\n",
    "    Train the model.\n",
    "    \n",
    "    Args:\n",
    "        model: The model to train.\n",
    "        criterion: The loss function.\n",
    "        optimizer: The optimizer.\n",
    "        train_loader: DataLoader for the training data.\n",
    "        val_loader: DataLoader for the validation data.\n",
    "        num_epochs (int): Number of epochs to train.\n",
    "    \n",
    "    Returns:\n",
    "        model: The trained model.\n",
    "    \"\"\"\n",
    "    for epoch in range(num_epochs):\n",
    "        # Set model to training mode\n",
    "        model.train()\n",
    "        running_loss = 0.0\n",
    "        for i, data in enumerate(tqdm(train_loader)):\n",
    "            inputs, labels = data\n",
    "            # Move data to the appropriate device\n",
    "            inputs, labels = inputs.to(device), labels.to(device)\n",
    "            \n",
    "            # Zero the parameter gradients\n",
    "            optimizer.zero_grad()\n",
    "\n",
    "            # Forward pass to get model outputs\n",
    "            outputs = model(inputs)\n",
    "\n",
    "            # Compute the loss\n",
    "            loss = criterion(outputs, labels)\n",
    "            # Backward pass to compute gradients\n",
    "            loss.backward()\n",
    "            # Update model parameters\n",
    "            optimizer.step()\n",
    "\n",
    "            # Accumulate the running loss\n",
    "            running_loss += loss.item()\n",
    "        \n",
    "        epoch_loss = running_loss / len(train_loader)\n",
    "        print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {epoch_loss}\")\n",
    "        \n",
    "        # Validation phase\n",
    "        # set the model to validation mode\n",
    "        model.eval()\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        # Disable gradient computation for validation\n",
    "        with torch.no_grad():\n",
    "            for data in val_loader:\n",
    "                images, labels = data\n",
    "                # Move validation data to the appropriate device\n",
    "                images, labels = images.to(device), labels.to(device)\n",
    "                outputs = model(images)\n",
    "                # Get the predicted class\n",
    "                _, predicted = torch.max(outputs.data, 1)\n",
    "                total += labels.size(0)\n",
    "                correct += (predicted == labels).sum().item()\n",
    "\n",
    "        print(f\"Validation accuracy: {100 * correct / total}%\")\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "53fb9594-29a2-4632-96ca-ce64e1033f15",
   "metadata": {},
   "source": [
    "## 6. Inference\n",
    "\n",
    "The inference function is designed to predict the class label of a given image using a trained neural network model. This process involves preprocessing the image, feeding it through the model, and interpreting the model's output to determine the most likely class.\n",
    "\n",
    "#### Key Steps in the Inference Process:\n",
    "\n",
    "1. **Image Preprocessing**:\n",
    "   - The image is preprocessed to match the input requirements of the model. This includes resizing, normalization, and converting the image to a tensor format compatible with PyTorch.\n",
    "\n",
    "2. **Model Evaluation**:\n",
    "   - The model is set to evaluation mode using `model.eval()`, which ensures that layers like dropout and batch normalization behave appropriately during inference.\n",
    "\n",
    "3. **Prediction**:\n",
    "   - The preprocessed image is passed through the model to obtain the output logits.\n",
    "   - The `torch.max` function is used to determine the class with the highest predicted probability, which is returned as the predicted label."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f9abfa98-551a-4911-8132-31edff9257f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_image(model, image_path):\n",
    "    \"\"\"\n",
    "    Predict the class of a sample image.\n",
    "    \n",
    "    Args:\n",
    "        model: The trained model.\n",
    "        image_path (str): Path to the image to predict.\n",
    "    \n",
    "    Returns:\n",
    "        int: Predicted class label.\n",
    "    \"\"\"\n",
    "    transform = T.Compose([\n",
    "        T.Resize((256, 256)),\n",
    "        T.ToTensor(),\n",
    "        T.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225]),\n",
    "    ])\n",
    "    image = Image.open(image_path).convert(\"RGB\")\n",
    "    # Apply the transformations and add a batch dimension\n",
    "    image = transform(image).unsqueeze(0)\n",
    "    image = image.to(device)\n",
    "\n",
    "    model.eval() # Set the model to evaluation mode\n",
    "    with torch.no_grad():\n",
    "        outputs = model(image)\n",
    "        _, predicted = torch.max(outputs, 1)\n",
    "        return predicted.item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4546286e-44af-49cc-985a-96e33f95aeb1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
