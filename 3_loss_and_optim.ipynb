{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "5097442d-5d99-49ff-acbe-4d2eb319b7d1",
   "metadata": {},
   "source": [
    "## 3. Loss function\n",
    "\n",
    "### Finding Loss Functions in PyTorch\n",
    "\n",
    "PyTorch offers a wide range of loss functions that cater to different types of tasks, from regression to classification. You can find a comprehensive list of available loss functions in the PyTorch documentation under the [Loss Functions](https://pytorch.org/docs/stable/nn.html#loss-functions) section. This resource provides details on each loss function, including their purpose, usage, and parameters, enabling you to choose the most suitable one for your specific application.\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "- **Purpose**:\n",
    "  - The code defines a loss function using `torch.nn.CrossEntropyLoss()`, which is commonly used for multi-class classification tasks.\n",
    "\n",
    "- **Functionality**:\n",
    "  - `CrossEntropyLoss` computes the cross-entropy loss between the predicted class probabilities (output logits from the model) and the true class labels.\n",
    "\n",
    "- **Use Case**:\n",
    "  - This loss function is appropriate when the model outputs raw scores (logits) for each class, and you need to determine how well these scores match the actual labels."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f8d0140a-fbb7-4d9d-aaac-281dda622dfa",
   "metadata": {},
   "source": [
    "## 4. Optimization algorithm\n",
    "\n",
    "### Finding Optimization Algorithms in PyTorch\n",
    "\n",
    "PyTorch provides a variety of optimization algorithms to help train neural networks efficiently. These optimizers adjust the model parameters based on the computed gradients to minimize the loss function. You can explore the available optimization algorithms in the PyTorch documentation under the [Optimizers](https://pytorch.org/docs/stable/optim.html) section. This resource details each optimizer's functionality, parameters, and typical use cases, allowing you to select the most appropriate one for your specific needs.\n",
    "\n",
    "### Code Explanation\n",
    "\n",
    "- **Purpose**:\n",
    "  - The code defines an optimizer using `optim.SGD`, which stands for Stochastic Gradient Descent, a popular optimization algorithm in machine learning.\n",
    "\n",
    "- **Functionality**:\n",
    "  - `SGD` updates the model's parameters by computing the gradients of the loss function and applying them to minimize the loss.\n",
    "  - `lr=0.001` specifies the learning rate, which determines the step size during each update. A smaller learning rate can lead to more stable convergence.\n",
    "  - `momentum=0.9` is used to accelerate the optimization process by helping the optimizer navigate through the parameter space more effectively. It does this by maintaining a running average of past gradients, reducing oscillations and improving convergence speed.\n",
    "\n",
    "- **Use Case**:\n",
    "  - This optimizer is suitable for training neural networks where you want to leverage simple, yet effective gradient descent techniques with additional momentum for faster convergence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a389975e-4c60-49a7-b50d-5cae196690f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.optim as optim\n",
    "\n",
    "from resnet18 import model\n",
    "\n",
    "# Define the loss function\n",
    "criterion = torch.nn.CrossEntropyLoss()\n",
    "\n",
    "# Define the optimizer\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.001, momentum=0.9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da678c7c-31d5-4982-a1b8-2258d73afcff",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
